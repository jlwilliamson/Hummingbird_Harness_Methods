---
title: "Cormack-Jolly-Seber Mark-Recapture Models"
author: "Jessie Williamson"
date: "Created 4/3/2021; last revised 4/28/21 "
output: html_document
---

Script for Williamson & Witt (In Revision), "A lightweight body harness for tracking hummingbirds". It includes: 
**1)** Code and extensive notations for Cormack-Jolly-Seber (CJS) models to estimate apparent survival and recapture probabilities from our geolocator birds *and* from our two satellite birds. AND, troubleshooting, diagnostic plots, and diagnostic test attempts. 
**2)** Code to produce Figure 3 comparing published survival rates for hummingbirds. 


**Background**
Cormack-Jolly-Seber models are mark-recapture models used to estimate two parameters:
1) Detection probability (*p*t, the probability of encountering a live animal at time t)
2) Apparent survival (*Φ*t, the prob of an animal surviving and remaining in the study area between time t and t + 1).

Note that “Apparent” survival confounds surviving *and* remaining in the study area. In this script, I use “survival” when describing apparent survival for simplicity.

---

```{R, echo=FALSE}
# I set some GLOBAL R chunk options here.
#   (to hide this message add "echo=FALSE" to the code chunk options)

knitr::opts_chunk$set(comment = NA, message = FALSE, warning = FALSE, width = 100)
knitr::opts_chunk$set(fig.align = "center", fig.height = 4, fig.width = 6)

#knitr::opts_chunk$set(cache = TRUE, autodep=TRUE)
knitr::opts_chunk$set(cache = TRUE, autodep=TRUE)
```


# Load packages
```{R}
library(reshape)
library(reshape2)
library(plyr)
library(dplyr)
library(car)
library(GGally)
library(Hmisc)
library(gridExtra)
library(stats)
library(gplots)
library(ggplot2)
library(stats4) # Forces knitr to work when it's being wonky
library(PMCMR) #Allows Kruskal-Wallis post-hocs
library(viridis)
library(lme4)
library(sjstats)
library(MuMIn)

library(marked) # for Cormack-Jolly-Seber models
# Make sure you don't have RMark simultaneously loaded because 'marked' and 'RMark' have many functions w/ the same names
library(R2ucare) # For Goodness of fit tests
library(unmarked)
library(magrittr) # for pipes
```


---

# Clear workspace and set WD
```{R}
rm(list=ls(all=TRUE)) # clear workspace 
setwd("/Users/Jessie/Dropbox (MSBbirds)/Rdirectory/Hummingbird_Harness_Methods")
```


# load in data 
```{R}
sl <- read.csv("TableS2_Hummingbird_Survival_Estimates_forR_04-15-21.csv", stringsAsFactors = TRUE) # Hummingbird survival rate lit review
cjs <- read.csv("Patagona_Cormack-Jolly-Seber_04-06-21.csv", stringsAsFactors = TRUE) # capture history data 
str(cjs) # Check data structures
# 'ch' capture histories must be characters! (And they're currently integers...)

# Alternative way to read in the data and deal w/ leading zeros
# test <- read.csv("capture_history.csv", stringsAsFactors = TRUE) 
# test <- test[ , !(colnames(test) %in% c("X"))] # drop weird X column 1 if reading in from read.csv
# test$ch <- sprintf("%03d", test$ch) # Another way to fix leading zeros if reading in from .csv (since R removes leading 0s)
# str(test)
```


# Wrangle & Subset data 
We want 'ch' capture histories (MAKE SURE THESE ARE CHARACTER STRINGS WITH LEADING ZEROS!) and tagging_age as a blocking variable. Can't use sex because can't ID Patagona to sex without gonads. 
```{r}
# Get the data into the format you need
capture.seasons <- c("Year1_Jan2017", "Year2_Nov2017.Jan2018", "Year3_Dec2018.Jan2019") # Define capture seasons
cjs$ch <- do.call(paste, c(cjs[capture.seasons], sep = ""))  # Apply do.call & create string capture histories 
# This makes a binary variable called 'ch' with 010 capture histories 
# Where each 0 represents lack of detection/capture
# And each 1 represents detection/capture 
# One row per individual; all capture histories must be of the same length

# Drop data for satellite birds because a history of "001" provides no information to the CJS model because 
# capture/non-capture status is only informative when conditioned on earlier captures 
cjs <- cjs[-which(cjs$tracking_device_type == "satellite_transmitter"),] 

# These don't solve my problem! More on this "111" and "101" convergence/math issue below.
# Update 101 to 111
#cjs[cjs$trackingID=="BC377" & cjs$ch=="101",][, "ch"] <- 111

# Test to see if removing 101 helps: 
# test <- cjs[-which(cjs$ch == "101"),]
```


# Subset data to capture history format you'll want for models
```{r}
# Create the data subset w/ just capture histories and tagging_age as a blocking variable
cjsdat <- subset(cjs, select = c(ch, # Capture history
                                 tagging_age
                                        ) )

str(cjsdat) # Good; ch format is character 
cjsdat <- na.omit(cjsdat) # shouldn't be NAs, but things are being a little weird so this is a precaution

write.csv(cjsdat, "/Users/Jessie/Dropbox (MSBbirds)/Rdirectory/Hummingbird_Harness_Methods/CaptureHistory_CJS.csv")
```


# Creating a basic CJS model
There are two components of the model (one for detection probability, one for survial probability). Each sub-model is a linear model (on a logit scale to bound probabilities between 0 and 1). We’ll start with the default model of constant detection probability and constant survival probability.

Use the crm() function, which calls three functions in term: 
1) `process.data` to process the data;
2) `make.design.data` to create the list of parameter-specific dataframes;
3) `cjs`, to fit the CJS model with the defined formulas.
```{r}
# Create a basic CJS model (constant survival and detection) with: 
cjs.basic <- crm(cjsdat, hessian=TRUE) # 47 capture histories collapsed into 8

# With this basic model I get a persistent error message: 
# Error in apply(ind, 1, function(x, z) rep(z[x[1]], x[3] - x[2] + 1), z = imat$freq) : 
#   dim(X) must have a positive length
```


*THE REASON FOR THIS ERROR* (this took a lot of digging to arrive at): 
Ultimately, small sample size and lack of detection of birds in Year2 that were tagged in Year1 (i.e., anything with a "11" in the first two characters) means that the behind-the-scenes math doesn't work. 

This is because without a level of "111", I can't calculate Phi1 to estimate survival from year 1 to year 2 (I can't get this estimate with the single level of "101" that I have from BC377). Essentially, the estimate for p2 = 0, and because I also have no "110"s, the estimate for Phi1p2 = 0. That means that when I go to calculate Phi1 (which is Phi1p2/p2, I get 0/0 = Error!).

- The easiest solution is to change our "101" from BC377 to "111", which would affect capture probability estimates but not survival. This also makes more sense and seems to be the most minor modification possible given that this bird *did* survive for two years. HOWEVER, When I make this change, the model still doesn't run. I can hand-calculate Phi1, Phi1p2, and p2, but I cannot get the model to run in R with this structure (more on these hand estimates below). I assume what's happening is that R knows something - a value - should exist to divide by, but instead it's coming up with a null/empty and can't compute. 
- Having multiple "101"s wouldn't help because p2 would still be zero. 
- And, having multiple "110"s wouldn't help, because I would get a value for Phi1p2, but I'd still be dividing by a denominator p2 of zero, which results in an error. 

**Two possible solutions**: 
**1)** Substitute one of our "011" Year 2-3 birds for "111" to fill missing gaps between Years 1-2. This should have negligible effects on survival and should keep capture probabilities consistent with what we observed. This would be the most conservative approach that does not inflate number of devices deployed, tags retrieved, and there's nothing I'll misinterpret with regard to year effects. 
**2)** Add in one dummy level of "111" in order that the matrix math behind the scenes works. But, adding one level of "111" will inflate survival and capture probability estimates slightly (I have also tried adjusting proportions of "111"s added in order to match the hand calculated survival and capture probabilities, and it just doesn't work). 

Since Option 1 (subbing "111" in for one "011" level) is the most parsimonious solution, we'll opt for that and assess "dummy levels" below (see diagnostic plots exploring these options).


# Update CJS data by swapping 011 for 111. 
```{R}
# This is essential to getting models to run! 
# Switch a 011 year 2-3 bird to a 111 to fill in missing levels for years 1-2
cjs2 <- cjs # Duplicate to retain original while modifying 
cjs2[cjs2$nk=="252134" & cjs2$ch=="011",][, "ch"] <- 111 # swap levels for this single adult bird 
cjsdat_adjusted <- subset(cjs2, select = c(ch, tagging_age)) # Modeling data frame w/ just capture histories + age
# I should now have one "111" bird and only five "011" birds
```


# Now fit the CJS model with updated data 
- We'll assume equal time intervals (time.interval argument) because all recapture attempts occurred during roughly the 
same window of the breeding season. But, if we do want to play with time, capture interval is 1/12 months = ~0.08/month (so ~0.17 for 2 month interval and 0.83 for 10 months; see Blake and Loiselle 2008)
- We will not consider a time-since capture (TSM) model because we have a relatively short study period (3 years), overall low sample size, and very low recapture rate. Additionally, this would only matter for one individual (BC377) because all others were recaptured in the year following initial deployment.
```{r}
# Create a basic CJS model (constant survival and detection) with:
cjs.m1 <- crm(cjsdat_adjusted, hessian=TRUE) # 47 capture histories collapsed into 8; hessian=TRUE gets precision estimates
cjs.m1
# A non-zero value for convergence means the model did NOT converge (aka, you want convergence = 0)

# Warning message:
# In optimx.check(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
#   Parameters or bounds appear to have different scalings.
#   This can cause poor performance in optimization. 
#   It is important for derivative free methods like BOBYQA, UOBYQA, NEWUOA.

# TAKE A LOOK AT MODEL OUTPUT AND ESTIMATES
# Estimates are on a logit scale, so let’s change them back to real estimates using the inverse logit. 
# You can calculate: 1) by hand; 2) w/ plogis(); 3) w/ predict(). All should give the same estimates.
# exp(cjs.m1$results$beta$Phi)/(1+exp(cjs.m1$results$beta$Phi)) # real Phi (survival) estimate by hand; change to p for p
# plogis(cjs.m1$results$beta$Phi) # Phi (suvrival) estimate with plogis; change to beta$p for p

predict(cjs.m1)
# $Phi= Probability of a Patagona surviving between capture events was 0.48
# $p = Probability of catching a Patagona during a capture event was 0.34
```

Note about this warning: Some googling retrieved a BioGeoBEARS page w/ descriptions of warnings that can and can't be ignored. Based on this page, it looks like I CAN ignore this warning message the model is throwing at me. 

Rationale from the site: ML searches seem to reach the same results whether or not this warning is thrown, as long as the ML parameter values actually are within the user-specified bounds.

More info here: http://phylo.wikidot.com/biogeobears-warnings-to-ignore-mostly

 
# NOW, ACTUALLY FIT AND COMPARE CJS MODELS  
We'll use James Paterson's function for generating subsets of models to fit and then compare models w/ a nice table output.
**See CUT script from code of James' I modified for individually specifying models to run.
```{r}
# It is good practice to follow these steps:
# 1. Process data
# 2. Create design data
# 3. Set-up and execute entire candidate model set
# The advantage is it is easier to add covariates (e.g. time-varying effects from weather or experiments)

# Process data (and set grouping variables)
cjs.proc <- process.data(cjsdat_adjusted, 
                         group = "tagging_age") # group variable has to be in the data

# Make design data (from processed data)
cjs.ddl <- make.design.data(cjs.proc)

# Function to fit multiple CJS models  
fit.cjs.models <- function(){
    
  # Apparent survival (Phi) formula
    Phi.dot <- list(formula = ~1) # constant survival
    Phi.age <- list(formula = ~tagging_age) # differs between adult and juv

    # Detection probability (p) formula
    p.dot <- list(formula = ~1) # constant detection
    p.age <- list(formula = ~tagging_age)  # differs between adult and juv

    # Construct all combinations and put into one model table
    cml <- create.model.list(c("Phi", "p")) # makes all possible combinations of those parameter formulas
    results <- crm.wrapper(cml, # crm.wrapper makes model sel table; stores results; in list stores model file names 
                           data = cjs.proc, 
                           ddl = cjs.ddl,
                           external = FALSE, 
                           accumulate = FALSE, 
                           hessian = TRUE)
    return(results)
}

# Run function
cjs.models <- fit.cjs.models()
cjs.models

# Pull models w/ list format (order given in order of # rows in table output):
# Listed from "best" to "worst": 
cjs.models[[4]] # Simplest model, Phi(.)p(.)
cjs.models[[2]] # Phi(~age)p(.)
cjs.models[[3]] # Phi(.)p(~age)
cjs.models[[1]] # Phi(~age)p(age)

predict(cjs.models[[4]]) # Predict from models in the set by calling brackets

# Top model is cjs.m1, so let's get our final estimates: 
cjs.top <- cjs.models[[4]]
predict(cjs.top)

cjs.global <- cjs.models[[1]] # Our most complex model, Phi(age)p(age)
```

What this model list tells us: 
- The top model is the simplest model that assumes constant survival and detection probability. 
- $Phi= Probability of a Patagona surviving between capture events was 0.51
- $p = Probability of catching a Patagona during a capture event was 0.28
 
 
# Based on these numbers, how many devices *might* we expect to retrieve? 
...fully acknowledging that this is a very coarse approximation...
```{R}
num.deployed <- 47
phi.best <- plogis(cjs.top$results$beta$Phi); phi.best
p.best <- plogis(cjs.top$results$beta$p); p.best

expected.num.surviving <- num.deployed*phi.best; expected.num.surviving
expected.recaps <- expected.num.surviving*p.best; expected.recaps
```

Based on these coarse approximations, we expect ~24 birds to survive (out of 47 on which we deployed devices), and we expect 6.85 (so in real life numbers, 6-7) devices to be recaptured. 
 
-----


# # EVALUATE GOODNESS OF FIT (GOF) AND OVERDISPERSION

# Set up data structures for GOF tests
```{r}
# Begin by recreating capture histories (aka, 0/1 histories spread across all 3 years of our sampling: 
# Full data
cjsdat.ch.gof <- cjsdat_adjusted$ch %>%
  strsplit('') %>%
  sapply(`[`) %>%
  t() %>%
  unlist() %>%
  as.numeric %>%
  matrix(nrow = nrow(cjsdat_adjusted))

# Adults only
cjsdat.adult.ch.gof <- cjsdat_adjusted$ch[cjsdat_adjusted$tagging_age == "adult"] %>%
  strsplit('') %>%
  sapply(`[`) %>%
  t() %>%
  unlist() %>%
  as.numeric %>%
  matrix(nrow = nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "adult",]))

# Juveniles only
cjsdat.juv.ch.gof <- cjsdat_adjusted$ch[cjsdat_adjusted$tagging_age == "juvenile"] %>%
  strsplit('') %>%
  sapply(`[`) %>%
  t() %>%
  unlist() %>%
  as.numeric %>%
  matrix(nrow = nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "juvenile",]))
```


**GOF TESTS in R2ucare:** 
- These tests have VERY confusing names and generally poor documentation (and online tutorials conflict descriptions written about tests in Gimenez et al. 2018). They do not go in order! i.e., Gimenez et al. describes running test2ct() and then test3sr() versus the two 'test2's and two 'test3's in order. 
- Test 1 = the omnibus or overall test ("overall_CJS"). It asks: Overall, is there evidence that animals have equal capture probabilities and equal survival? Tells us if there’s a problem, but not where (which events) or why (which assumption is violated).
- Tests 2 (Test2.CT and Test2.CL) and Tests 3 (Test3.SR and Test3.SM) test for the effects of transients and trap-dependence. Tutorials online describe them as evaluating the effects of marking on survival, but the Gimenez et al. 2018 paper introducing the tests does not describe them that way. 

Generally, try Test 1 (overall_CJS()), and if there is evidence of lack-of-fit, use Test 2 and Test 3 to determine which assumptions are violated. Note: These tests are always for time-dependent models, i.e. “Phi.time.p.time”.


# GOF test 1: 'overall_CJS'
Try on full data, then just adults, then just on juvs
```{r}
# 1st argument = capture history matrix (made above)
# 2nd argument = capture history frequency (vector of 1's for our example)
# FYI, this test is the gum of 4 component tests with the worst names in history: Test3.SR, Test3.SM, Test2.CT and Test2.CL

overall_CJS(cjsdat.ch.gof, rep(1,nrow(cjsdat_adjusted))) # All data 
overall_CJS(cjsdat.adult.ch.gof, rep(1,nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "adult",]))) # Adults only
overall_CJS(cjsdat.juv.ch.gof, rep(1,nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "juvenile",]))) # Juvs only
# When I run all of these I get the following message: Error in m[rw, cl] : subscript out of bounds

# As a workaround, see if it helps to manually create frequency matrices and call those for second argument??
# make freq vectors: 
cjsdat.freq <- rep(1,nrow(cjsdat_adjusted))
cjsdat.adult.freq <- rep(1,nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "adult",]))
cjsdat.juv.freq <- rep(1,nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "juvenile",]))

overall_CJS(cjsdat.ch.gof, cjsdat.freq)
overall_CJS(cjsdat.adult.ch.gof, cjsdat.adult.freq) # Adult overall
overall_CJS(cjsdat.juv.ch.gof, cjsdat.juv.freq) # juv overall

# CANNOT RUN TEST
# Error in m[rw, cl] : subscript out of bounds
```

From somewhere online: In other words: If you are receiving the error message “subscript out of bounds” you should check whether you are trying to use a data element that does not exist in your data.

I spoke with Olivier Gimenez, creator of the R2ucare package, on 4/6/21, and he said that I'm likely running into problems due to small sample sizes. James Paterson agreed, and mentioned that because frequency test comparisons are made between cohorts, and because many of my cohorts are empty, I'm also likely seeing problems for this reason. 



Let's try performing individual tests for the full dataset and data subsets to better understand the components and how they’re related.

# 2) Test 2.CT: Is there an effect of trap dependence? 
Tests whether there is a difference in *p* (capture probability) at t+1 between those captured and not captured at t when animals are known to be alive because they are recaptured later in the study (Paterson blog)
Null hypothesis: Missed individuals have the same chance to be recaptured at the next occasion as currently captured individuals (Gimenez et al. 2018)
```{R}
# first argument = capture history matrix, second argument is frequency of each capture history (1 for example)

# try w/ all data 
test2ct_all <- test2ct(cjsdat.ch.gof, rep(1,nrow(cjsdat_adjusted))) 
test2ct_all

# Try w/ adult data 
test2ct_adult <- test2ct(cjsdat.adult.ch.gof, rep(1,nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "adult",]))) 
test2ct_adult

# CANNOT RUN TEST
# Error in m[rw, cl] : subscript out of bounds
```


# 3) Test3.SR: Is there an effect of transients? 
Does marking affect survival? Do individuals with previous marks have different survival rates than first-time captures?
Null hypothesis: Newly encountered individuals have the same chance to be later re-observed as recaptured (previously encountered) individuals (Gimenez et al. 2018)
```{r}
# try w/ all data 
test3sr_all <- test3sr(cjsdat.ch.gof, rep(1,nrow(cjsdat_adjusted))) 
test3sr_all
# X^2 chi square = 1.513
# p = 0.219
# df = 1.0
# sign test = 1.23

# Try w/ adults 
test3sr_adult <- test3sr(cjsdat.adult.ch.gof, rep(1,nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "adult",])))
test3sr_adult
# X^2 chi square = 1.409
# p = 0.235
# df= 1.0
# sign test = 1.187

# Try w/ juvs 
test3sr_juv <- test3sr(cjsdat.juv.ch.gof, rep(1,nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "juvenile",])))
test3sr_juv
# Juvs = not enough levels to run

# Finally, a test that runs! 
```

Conclusion of `Test3.SR`: We evaluated and found no effect of transients (χ2 = 1.51, df = 1.0, p = 0.22).
Positive sign test indicates an excess of marked individuals that were never seen again (Gimenez et al. 2018).


According to Gimenez et al. 2018, we now perform the two remaining tests: 

# 4) Test3.SM: For animals seen again, does when they are recaptured depend on whether they were marked on or before time t? (Paterson blog)
Null hypothesis: Among those individuals seen again, when they were seen does not differ among previously and newly marked individuals (Gimenez et al. 2018)
```{r}
# try w/ all data 
test3sm_all <- test3sm(cjsdat.ch.gof, rep(1,nrow(cjsdat_adjusted))) 
test3sm_all

# try w/ adults 
test3sm_adult <- test3sm(cjsdat.adult.ch.gof, rep(1,nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "adult",])))
test3sm_adult

# Sad :( 
# test_perf = none means that no tests were performed for test2cl because of low sample sizes
# These tests use contingency tables, so higher cell counts (more captures and recaptures will increase ability to perform
# tests)
```

Conclusion of `Test3.SM`: No tests performed due to small sample sizes. 


# 5) Test2.CL: Tests whether there is a difference in the expected time of next recapture between individuals captured and not captured at t when animals are known to be alive (Paterson blog).
Null hypothesis: There is no difference in the timing of re-encounters between the individuals encountered and not encountered at occasion i, conditional on presence at both occasions i and i + 2 (Gimenez et al. 2018)
```{R}
# try w/ all data 
test2cl_all <- test2cl(cjsdat.ch.gof, rep(1,nrow(cjsdat_adjusted))) # Error in rep(NA, km4) : invalid 'times' argument
test2cl_all

# try w/ adults
test2cl_adult <- test2cl(cjsdat.adult.ch.gof, rep(1,nrow(cjsdat_adjusted[cjsdat_adjusted$tagging_age == "adult",])))
test2cl_adult

# CANNOT RUN TEST, but different error this time:  
# Error in rep(NA, km4) : invalid 'times' argument
```


**Results from GOF tests**:  We evaluated and found no effect of transients (χ2 = 1.51, df = 1.0, p = 0.22) but were unable to perform other GOF tests due to small capture and recapture sample sizes. 


-----


Let's put our survival rates into context by comparing them to the survival rates of other hummingbird species from the literature. 

# PLOT: Point estimate comparison of hummingbird survival rates from the literature
```{r}
# First set levels so data appears in proper order 

# library(forcats) # This is easiest way, but this blanket-relevels by species, which we don't want
# sl <- sl %>% mutate(species = fct_reorder(species, species_num)) # now relevel based on plot.order 
# levels(sl$species) # check that releveling worked 

sl$common_name <- factor(sl$common_name
                       , levels = c("Ruby-throated Hummingbird_F1",
                                    "Ruby-throated Hummingbird_M1", 
                                    "Ruby-throated Hummingbird_F2", 
                                    "Ruby-throated Hummingbird_M2", 
                                    "Ruby-throated Hummingbird_F3", 
                                    "Ruby-throated Hummingbird_M3", 
                                    "Ruby-throated Hummingbird_F4",  
                                    "Ruby-throated Hummingbird_M4",
                                    "Mexican Violetear",
                                    "White-eared Hummingbird",
                                    "Long-tailed Hermit",
                                    "Green-billed Hermit_1",
                                    "Green-billed Hermit_2",
                                    "Speckled Hummingbird",
                                    "Green-crowned Brilliant",
                                    "Long-billed Hermit",
                                    "Hyacinth Visorbearer_F",
                                    "Hyacinth Visorbearer_M",
                                    "Giant Hummingbird"))

FigureS3 <- ggplot(data=sl, aes(x=common_name, y=phi)) + 
      geom_hline(yintercept=0.42, linetype="longdash", size=0.4, color="red2", alpha=0.5) +
      geom_errorbar(aes(ymin=phi_lci, ymax=phi_uci), width=0.0, size=4.1, color="grey84") + # CI
      geom_errorbar(aes(ymin=phi-phi_se, ymax=phi+phi_se), width=0.13, size=1, color="gray28") + # se; purple 3 is pretty
      geom_point(data=sl[sl$sex=="female",], aes(y=phi, x=common_name), # Plot female points
            shape=16, color="goldenrod2", size=6) +
      geom_point(data=sl[sl$sex=="male",], aes(y=phi, x=common_name), # Plot male points another color 
            shape=16, color="turquoise3", size=6) + 
      geom_point(data=sl[sl$sex=="species-level",], aes(y=phi, x=common_name), # Plot species-level estimates in black
            shape=16, color="black", size=6) +
     # geom_point(mapping=aes(y=phi), size=5, shape=21, fill="black") + # Plot all points at once 
      scale_y_continuous(limits=c(0,1.0), breaks=c(0,0.25,0.5,0.75,1.0)) +
      scale_x_discrete(labels=c("Archilochus colubris [1]", "Archilochus colubris [1]", "Archilochus colubris [2]", 
                                "Archilochus colubris [2]", "Archilochus colubris [3]", "Archilochus colubris [3]",
                                "Archilochus colubris [4]", "Archilochus colubris [4]", "Colibri thalassinus", 
                                "Hylocharis leucotis", "Phaethornis superciliosus", "Phaethornis malaris [5]", 
                                "Phaethornis malaris [6]","Adelomyia melanogenys", "Heliodoxa jacula", 
                                "Phaethornis baroni","Augastes scutatus [7]", "Augastes scutatus [7]", "Patagona gigas")) +
      theme_classic() +     
      theme(axis.text.x=element_text(angle=45, hjust=1.0)) + 
          # ggtitle("(a)") + 
      theme(plot.title.position="plot", plot.title = element_text(face="bold")) + 
          # parameter "plot" specifies that you want "title" flush with y-axis; bold face makes panel header bold 
          # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
      labs(x="Species", y = expression("Survival Estimate"~"("~italic(phi)~")")) + # Phi is supposedly italicized...
      theme(axis.title=element_text(size=12), axis.text.y=element_text(size=12), axis.text.x=element_text(size=10, face="italic")) # These go: y-axis title, y-axis ticks, x-axis species labels (italic)
print(FigureS3)
ggsave(FigureS3, filename="FigureS3_SurvivalRateComparison_04-29-21.pdf", height=7, width=9, units="in")

# REFS: Charette et al. = [1]; Mulvihill et al. 1992 = [2]; Baumgartner 1989 = [3]; Hilton & Miller 2003 = [4]; 
# Blake & Loiselle 2008 = [5]; Blake & Loiselle 2013 = [6]; Rodrigues et al. 2013 = [7]
```
 
 
# End of data presented in our paper (but not end of script)


----


Now, let's revisit sensitivity to our data of adding levels, and diagnostic tests we completed during this lengthy exploration process to arrive at the conclusions presented above. 
 
# TEST OF SENSITIVITY TO ADDING LEVELS 

# By *how much* does adding in a single "111" level inflate annual survival and capture probability estimates? --> 
# Manually calculate p2, Phi1p2, and Phi1 for year 2
```{r}
# my data: 101 = 1; 111 = 0; 110 = 0
# My data w/ dummy "111" 101 = 1; 111 = 1; 110 - 0
# Adjust these numbers to come up with estimates 
one_zero_one <- 1
one_one_one <- 1 # Change this number to look at the effect of adding in a dummy level of "111"
sum1 <- one_zero_one + one_one_one
one_one_zero <- 0
geos2017 <- sum(cjs$ch=="100") + sum(one_zero_one) + sum(one_one_one); geos2017 # true # deployed + # of dummy 111s to add
# Should be 16 geos deployed in 2017 and 17 if considering dummy 

p2 <- one_one_one/sum1; p2 # probability of capture in year 2
Phi1p2 <- one_one_one/geos2017; Phi1p2 # probability that animal survives from year1 to year 2 and is detected in year 2
Phi1 <- Phi1p2/p2; Phi1 # estimated survival for year 1

# Test 1: 
# Confirmed: with my data the way they are (101 = 1; 111 - 0), it is impossible to calculate survivorship 
# for year 1 (Phi1)!! (This results in "NaN")

# Test 2: 
# IF I change "101" into "111" then Phi1 = 0.0625; this checks out with my hand-calculations

# Test 3: 
# When I add in "111" of 1, survivorship for year 1 becomes 0.117
# And capture probability is inflated

# How is survival estimate (Phi1) affected? 
Phi1_real <- 0.0625 # This is true estimate calculated by changing the BC377 101 into 111
Phi1_dummy <- 0.1176471
Phi1_diff <- Phi1 - Phi1_real; Phi1_diff
# Adding in that single "111 individual" inflates Phi1 survival estimate by ~5.5%

# How is probability of capture estimate (p2) affected? 
p2_real <- 0 # This is true estimate calculated by changing the BC377 101 into 111
p2_dummy <- 0.5 # Alternatively, use: one_one_one/sum(one_one_one + one_zero_one)
p2_diff <- p2_dummy - p2_real; p2_diff
# Adding in that single "111" individual inflates p2 capture estimate by 50%
```

So: Adding in a single "dummy" level of "111" in order to make the model converge and make the matrix math work increases year 1 survival estimate (Phi1) by 0.055 (5.5%) and capture probability by 0.5 (50%). This does NOT mean that this is the proportion by which annual estimates of survival and capture probability increase, however. This is definitely a less-than-ideal solution to model convergence issues due to small sample sizes. 

But let's try generating a dataset w/ a dummy level of "111" anyways...

# Update CJS data with dummy "111" level 
```{r}
# Must have this "111" level in order to estimate year 1 survival and capture probabilities
cjsdat_adjusted <- rbind(cjsdat, data.frame(ch = c(rep("111", 1)), tagging_age = rep("adult", 1)))

# If incorporating multiple levels (unneccessary and we don't want this!)
# cjsdat_adjusted <- rbind(cjsdat,
#                                 data.frame(ch = c(rep("001", 1),
#                                                   rep("111", 1)),
#                                                   tagging_age = rep("adult", 1)))

write.csv(cjsdat_adjusted, "/Users/Jessie/Dropbox (MSBbirds)/Rdirectory/Hummingbird_Harness_Methods/CaptureHistory_CJS_adj.csv")
```


We know we have no option but to add a level of "111" OR to swap a level of "011" for "111" in order to get our models to converge. We've assessed (above) the impacts to Phi1 and p2 of adding a single level of "111" to our data, but now we're curious about how, more broadly, the addition of data affects estimates. **To assess this** we'll quickly compare the "Swap 011 for 111" dataset with "dummy" datasets with different levels of "111" added (point estimates, standard errors, and CIs).
```{R}
# What happens if I switch a 011 year2-3 bird to a 111 to fill in years 1-2?
# NOTE: THIS SWAPPING SOLUTION IS WHAT WE WENT WITH FOR OUR PAPER BECAUSE IT WAS THE MOST PARSIMONIOUS AND IMPACTED
# SURVIVAL AND CAPTURE PROBABILITY ESTIMATES LEAST
test <- cjs # quick copy data frame 
test[test$nk=="252134" & test$ch=="011",][, "ch"] <- 111 # swap levels 
tdat <- subset(test, select = c(ch, # Capture history
                                 tagging_age
                                        ) )
cjs.test <- crm(tdat, hessian=TRUE) # 47 capture histories collapsed into 8
predict(cjs.test) # No dummy but swap 011 for 111; Phi = 0.51; p = 0.28

# Now, how sensitive are tests to dummy levels? 
# Make dummy trial datasets 
cjsdat.2level <- rbind(cjsdat, data.frame(ch = c(rep("111", 2)), tagging_age = rep("adult", 2)))
cjsdat.3level <- rbind(cjsdat, data.frame(ch = c(rep("111", 3)), tagging_age = rep("adult", 3)))
cjsdat.4level <- rbind(cjsdat, data.frame(ch = c(rep("111", 4)), tagging_age = rep("adult", 4)))
cjsdat.5level <- rbind(cjsdat, data.frame(ch = c(rep("111", 5)), tagging_age = rep("adult", 5)))
cjsdat.6level <- rbind(cjsdat, data.frame(ch = c(rep("111", 6)), tagging_age = rep("adult", 6)))

# Run tests and get estimates from Phi(.)p(.) models 
cjs.m1; predict(cjs.m1) # 1 dummy level of 111; Phi = 0.48, p = 0.34

cjs.2level <- crm(cjsdat.2level, hessian=TRUE)
predict(cjs.2level) # 2 dummy levels of 111; Phi = 0.45, p = 0.43

cjs.3level <- crm(cjsdat.3level, hessian=TRUE)
predict(cjs.3level) # 2 dummy levels of 111; Phi = 0.44, p = 0.51

cjs.4level <- crm(cjsdat.4level, hessian=TRUE)
predict(cjs.4level) # 2 dummy levels of 111; Phi = 0.44, p = 0.58

cjs.5level <- crm(cjsdat.5level, hessian=TRUE)
predict(cjs.5level) # 2 dummy levels of 111; Phi = 0.44, p = 0.63

cjs.6level <- crm(cjsdat.6level, hessian=TRUE)
predict(cjs.6level) # 2 dummy levels of 111; Phi = 0.45, p = 0.88

# Make a data frame with # levels, survival estimates, capture prob estimates, and confidence intervals
sensitivity <- data.frame(
              "dataset" = c("Dummy_0_Swap011For111", "Dummy_1level", "Dummy_2level", "Dummy_3level", "Dummy_4level", 
                            "Dummy_5level", "Dummy_6level"), 
              "phi" = c(0.5119027, 0.4835739,0.452329,0.4399577,0.4375787,0.4408579,0.4474458), 
              "phi_se" = c(0.3679488, 0.3181648,0.2505397,0.2071456,0.1772325,0.1555582,0.1392401),
              "phi_lcl" = c(0.0552666,0.07156895,0.1021542,0.1313451,0.1594271,0.1862501,0.2116792),
              "phi_ucl" = c(0.9495006,0.919189,0.857048,0.8032053,0.7614249,0.7309014,0.7094761),
              "p" = c(0.2848852, 0.337624, 0.4334863,0.5146297,0.5817116,0.6367171,0.6818362),
              "p_se" = c(0.2505484,0.2685021, 0.2845168,0.282199,0.2697917,0.2527882, 0.2343671),
              "p_lcl" = c(0.03452859,0.04621478, 0.07320711, 0.1037905, 0.1366493, 0.1706729,0.2050102),
              "p_ucl" = c(0.8160956,0.8428168, 0.881128, 0.9066052,0.9243526, 0.9372125,0.9468346)
              )
```


# PLOT: Make a boxplot with confidence intervals showing how estimates shift w/ inclusion of swap vs. dummy data
```{R}
# Phi (survival estimates)
survival.comp <- ggplot(sensitivity, aes(x=dataset, y=phi)) + 
      geom_errorbar(mapping=aes(ymin=phi_lcl, ymax=phi_ucl), width=0, size=4.1, color="grey60", alpha=0.5) + # CIs
      geom_errorbar(mapping=aes(ymin=phi-phi_se, ymax=phi+phi_se), width=0.07, size=1, color="firebrick") + # se
      geom_point(mapping=aes(y=phi), size=5, shape=21, fill="black") +
     # coord_flip() + 
      scale_y_continuous(limits=c(0,1.0), breaks=c(0,0.25,0.5,0.75,1.0)) +
      scale_x_discrete(labels=c("Swap 011 for 111", "1 Dummy Level", "2 Dummy levels",
                                "3 Dummy Levels", "4 Dummy Levels", "5 Dummy Levels", "6 Dummy Levels")) +
      theme_classic() +     
      theme(axis.text.x=element_text(angle=45, hjust=1.0)) + 
          # ggtitle("(a)") + 
      theme(plot.title.position="plot", plot.title = element_text(face="bold")) + 
          # parameter "plot" specifies that you want "title" flush with y-axis; bold face makes panel header bold 
          # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
      labs(x=" ", y = expression("Survival Rate"~"("~italic(phi)~")")) + # x blank because label in bottom panel below
      theme(axis.title=element_text(size=12), axis.text.y=element_text(size=12), axis.text.x=element_text(size=10)) # These go: y-axis title, y-axis ticks, x-axis species labels (italic)
print(survival.comp)
ggsave(survival.comp, filename="SurvivalEstimateComparison_TestDatasets_DummyData.pdf", height=7, width=9, units="in")
  

# p (Probablity of capture estimates)
capture.comp <- ggplot(sensitivity, aes(x=dataset, y=p)) + 
      geom_errorbar(mapping=aes(ymin=p_lcl, ymax=p_ucl), width=0, size=4, color="grey60", alpha=0.5) + # CIs 
      geom_errorbar(mapping=aes(ymin=p-p_se, ymax=p+p_se), width=0.07, size=1, color="dodgerblue2") + # se
      geom_point(data=sensitivity, mapping=aes(y=p), size=5, shape=21, fill="black") +
     # coord_flip() + 
      scale_y_continuous(limits=c(0,1.0), breaks=c(0,0.25,0.5,0.75,1.0)) +
      scale_x_discrete(labels=c("Swap 011 for 111", "1 Dummy Level", "2 Dummy levels", 
                                "3 Dummy Levels", "4 Dummy Levels", "5 Dummy Levels", "6 Dummy Levels")) +
      theme_classic() +     
      theme(axis.text.x=element_text(angle=45, hjust=1.0)) + 
          # ggtitle("(a)") + 
      theme(plot.title.position="plot", plot.title = element_text(face="bold")) + 
          # parameter "plot" specifies that you want "title" flush with y-axis; bold face makes panel header bold 
          # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
      labs(x="Test Dataset", y = expression("Capture Probability"~"("~italic(p)~")")) + 
      theme(axis.title=element_text(size=12), axis.text.y=element_text(size=12), axis.text.x=element_text(size=10)) # These go: y-axis title, y-axis ticks, x-axis species labels (italic)
print(capture.comp)
ggsave(capture.comp, filename="CaptureProbabilityComparison_TestDatasets_DummyData.pdf", height=7, width=9, units="in")

library(patchwork)
dummy.data.comparison.plot <- (survival.comp / capture.comp +  # the / literally means put p14 on top of p15
                                  plot_layout(guides = "collect")) # "collates" and combines one common legend 
                                  # In order for plot_layout to "collect" legend, must have printed legend for indiv plots above
plot(dummy.data.comparison.plot)

ggsave(dummy.data.comparison.plot, filename = "Dummy_Data_Comparison_Plot.pdf", bg="transparent", height=6, width=5, units="in")
```

**What these plots tell us**: 
- Survival estimates are remarkably stable (in fact, they decrease *slightly* when we add more dummy levels). The se and CI estimates shrink (i.e., get better) with the more data we add - this is to be expected. The good news: Increasing dummy data doesn't affect point estimates much at all (though we do gain more confidence in these estimates), **and** there isn't a substantive difference in surival rate for Phi(.)p(.) moddels between "Swap 011 for 111" data and "1 dummy level of 111" data. 
- Probability of capture increases somewhat predictably as we increase the number of dummy levels in the data. *p* is lowest for the "Swap 011 for 111" dataset, suggesting that adding a single level of 111 has the greatest impact on estimates of *p* in the model. 
- To clarify: We opted for the "swap 011 for 111" method for our paper (most parsimonious, has the smallest effect on estimates), describe this in Methods, and leave these process notes here for transparency and reproducibility. Ah, the quirks of working with a small dataset!

See cut script for brief explanation of CJS models with release bird data as a proxy for "control" birds - short story: it's not advisable. 


--------

**Tutorials on Cormack-Jolly-Seber models:** 

James Paterson GitHub Repo: https://github.com/jamesepaterson/markrecaptureworkshop
James Paterson Creating Capture Histories in R: https://jamesepaterson.github.io/jamespatersonblog/07_creatingcapturehistories
James Paterson CJS models in R: https://jamesepaterson.github.io/jamespatersonblog/2020-04-26_introduction_to_CJS.html

Theory and Background on CJS models: https://www.montana.edu/rotella/documents/502/CJS.pdf

Clark Rushing Applied Bayesian Analysis for Ecological Data course: https://rushinglab.github.io/WILD6900/index.html
Clark Rushing Basic CJS models w/ dipper data: https://rushinglab.github.io/WILD6900/articles/cjs.html

'marked' package vignette: https://cran.r-project.org/web/packages/marked/vignettes/markedVignette.html

Troubleshooting and solving error 'dim(x) must have positive length' (*but it didn't help me*): https://statisticsglobe.com/r-error-in-apply-dim-must-have-positive-length

CJS tutorial from Montana: https://www.montana.edu/rotella/documents/502/CJS-intro.html#multinomial_distribution

Describes structure for time-dependent models: http://rstudio-pubs-static.s3.amazonaws.com/11453_e5657d3e0ee745afa5c797180d4fe829.html

A breakdown of distinct capture history profiles and contributions to likelihood: https://mc-stan.org/docs/2_26/stan-users-guide/mark-recapture-models.html

Another 'marked' tutorial: http://rstudio-pubs-static.s3.amazonaws.com/11453_e5657d3e0ee745afa5c797180d4fe829.html

phi.dot.org - advice for adding time-since-marking data: http://www.phidot.org/forum/viewtopic.php?f=21&t=2591

Laake et al. 2013 - Marked package vignette: https://cran.r-project.org/web/packages/marked/vignettes/markedVignette.html



--------


# Print environment for reproducibility
```{r}
sessionInfo()
```


# End 

